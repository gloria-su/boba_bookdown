--- 
title: "An Analysis of Boba Yelp Reviews"
author: "Violet Evans and Gloria Su"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---

# Introduction
Here, we present a background of our 2023 statistical side project: An Analysis of Boba Yelp Reviews. This project is co-authored by two M.S. in Analytics students at North Carolina State University, Violet Evans and Gloria Su. The inspiration behind our side project came from our love for bubble tea, a stable of Asian American culture. 

Bubble tea, also known as boba, is a sweet Taiwanese drink that has grown in popularity across the world since 1988 (https://www.nationalgeographic.com/travel/article/what-is-boba-bubble-tea-taiwan). Much of this growing popularity started from a new generation of young Asian Americans, who spread the drink to friends and neighbors from all different cultural backgrounds (https://www.eater.com/2019/11/5/20942192/bubble-tea-boba-asian-american-diaspora). As Asian Americans raised in North Carolina, we frequently longed for authentic Asian cuisines in the Triangle that would reconnect us with our heritage. Growing up, boba culture wasn't large. However, the popularity of boba in the broader Raleigh-Durham-Chapel Hill area (the Triangle) has surged, coinciding with the arrival of nearly 40,000 households and businesses between 2018 and 2022. This growth has brought a number of trendy Asian boba shops to the Triangle region. Not only has the number of shops increased, but there also has been a rise in the count of Yelp reviews for each individual shop.

Due to the extensive variety of boba shop offerings, spanning from milk tea and fruit tea to matcha with various toppings, in our experience, there have never been widely recognized standards for defining a good drink. Our project aim is to address this question by analyzing Yelp reviews.

The inspiration behind our Yelp API project came from a day in the library after studying for our statistical foundations class. We were chatting about our favorite boba drinks, and the conversation led to our own debate over what truly was the best boba shop in the area. One idea led to another, and we began delving into what a statistical side project could look like on a topic we were invested in— and thus began “An Analysis of Boba Yelp Reviews.”


<!--chapter:end:index.Rmd-->

# Data
Utilizing Python and the Pandas library, we initiated the web scraping process to compile our final data set in the CSV format. 

## Data Extraction

Our data extraction process began with leveraging the Yelp Fusion API, a tool that provides access to Yelp's extensive global business directory. To initiate this process, we submitted a developer application for a private API key through the Yelp Fusion website. Fortunately, the acquisition of the API key was practically instantaneous, and the method to define the appropriate endpoint for our queries was fairly straightforward. More specifically, we used the ‘businesses search’ endpoint to search the Yelp database and retrieve information about businesses, including location, category, or keywords.

However, our interaction with the Yelp Fusion API was not without limitations. Notably, businesses lacking any Yelp reviews would not be returned by the API, leading to the exclusion of new boba establishments. Furthermore, the API imposed restrictions, limiting us to 500 API calls per day and capping reviews per business at three.

To optimize the efficiency of data retrieval from the API, we implemented a Yelp API wrapper obtained from the GitHub repository authored by @gfairchild. The Yelp API wrapper functioned as an intermediary layer, simplifying the communication process between our system and Yelp's data services. By leveraging the wrapper, we were able to enhance the clarity of our code and simplify the technical intricacies associated with making requests directly to the API.

Having secured access to the Yelp Fusion API, we moved on to defining the variables for our analysis. Despite Yelp offering a diverse array of information, we encountered instances where certain data fields, such as price or wifi, contained many null values. We chose to move forward by discarding variables where the number of null values exceeds 50% of the total number of values and omitted the price and wifi variables given from Yelp. We moved forward in our analysis with the variables listed below.

```{r, include=FALSE}
boba <- read.csv("~/boba/Data/final_all.csv")
head(boba)
```

Each shop, which is also each Yelp entry, is designated with up to 3 tags. These include phrases like “Bubble Tea” or “Coffee Shop”. We filtered on the tag “Bubble Tea” to finish designating our data sets for both Raleigh and New York City (NYC). The source variable attaches each shop to a location.

Before proceeding with the modeling phase, we conducted further data manipulation. Specifically, we employed string splitting on the tags to create binary indicator variables for each of the shop’s categories. A shop could have three categories at maximum. For instance, a binary indicator variable for bubble tea was set to 1 if the observation fell under the bubble tea category and set to 0 otherwise. This approach allowed us to capture nuanced insights for a more comprehensive analysis of boba shops in the Raleigh and NYC areas.

This concluded the iterative process to achieve a final data set. Below is a snippet of the data table with binary indicator variables for each category.
```{r, echo=FALSE}
boba2 <- read.csv("~/boba/Data/slide_final.csv")
head(boba2)
```

After achieving a final data set, we split it into two data sets by location. This work can be found in the R folder of the Xiaolongbao respository under the week 11 RMD. Raleigh had n= 44 observations while NYC had n= 70 observations, each with different column counts due to the category tag columns. Raleigh had 28 columns, while NYC had 31 columns. The following variables formed the core of our analysis:

 - Name 

 - Rating

 - City

 - Categories

 - Review Count

 - Source

Additional variables like chain, authenticity, and restaurant were imputed by using external sources such as Google and our own expertise.

## Data Exploration
Prior to analysis, we performed some exploratory data analysis in RStudio. Yelp's ratings and reviews work by allowing users to rate businesses on a scale of 1 to 5 stars and write a review about their experiences (https://reviewsonmywebsite.com/blog/yelp-reviews#:~:text=reach%20more%20customers.-,How%20do%20Yelp%20ratings%20and%20reviews%20work%3F,on%20a%20business%27s%20Yelp%20page). One of the most thought-provoking visualizations we crafted was a boxplot comparing the ratings of boba shops in Raleigh and NYC, pictured below in Figure 1. 

```{r, echo=FALSE}
library("ggplot2")

boxplot(Rating~as.factor(source),data=boba2, main="Rating Distribution",
   xlab="Location", ylab="Rating (1-5)", names=c("NYC","Raleigh"))
```

Contrary to our initial expectations, the boxplot revealed that Raleigh-based boba shops exhibited higher ratings compared to their counterparts in NYC by 0.35 stars on average. We expected NYC to have higher ratings than Raleigh since this location is known as a “haven for Chinese cuisine,” including boba (https://www.foodydata.com/post/which-american-city-has-best-chinese-food#:~:text=New%20York%20is%2C%20of%20course,Chinese%20food%20is%20most%20popular). While the initial observation suggested a divergence in ratings between the two regions, we sought a more rigorous approach to quantify this difference. Consequently, we conducted a statistical test to assess the significance of the observed variations in ratings between Raleigh and NYC, highlighted section 3. 


<!--chapter:end:02-data.Rmd-->

# Methodology and Results
## Statistical Tests 
Prior to conducting any statistical tests, we checked the assumptions for normality, equal variance, and independence. Since we had a relatively small data set, we used the Shapiro-Wilk test to assess whether the shops are normally distributed and Levene's test for equality of variances (F-test) between shops in Raleigh and NYC. While the normality assumption did not hold (p= 3.81 x 10-4), we were able to confirm the equality of variances (p= 0.81). For the independence assumption, we assumed each shop was independent; however, we created a feature called “chain” that provided a binary flag if a shop had multiple locations. 

Thus, we performed Welch’s 2 sample t-test on the two different groups. We found that boba shops in Raleigh were significantly different from boba shops in NYC, with a p-value of 4e-03. All statistical tests utilized a significance level (alpha) of 0.05. The mean rating of shops in Raleigh was 4.16 (variance 0.32), while the mean rating in NYC was 3.84 (variance 0.35). This resulted in a difference in means of 0.35, as seen in Figure 1 in the previous section.

With our intial hypothesis confirmed by the statistically significant difference, our focus shifted to a more detailed comparison of boba shops in Raleigh and NYC. We decided to approach the problem with both an explanatory and predictive approach, running both a linear regression model for explainability and a predictive random forest model to find predictors of boba shop ratings.

## Linear Regression Model
To utilize an explanatory approach, we built two different variable selection models with rating as the target variable using stepwise regression. One model was for Raleigh while the other model was for New York City. After setting a full model and an empty model separately for the Raleigh and NYC datasets, we ran stepwise selection with k, the number of model parameters, set to 2 for both locations. The following code chunks display the stepwise selection code.

### Raleigh Variable Selection 
```{r, include=FALSE, eval=FALSE}
#import library
library("tidyverse")
#filter to only Raleigh variable selection
raleigh_df <- boba2[boba2$source=="raleigh_boba",]
#Make the binary columns 13 to 31 as factors
raleigh_df[, c(9:27)] <- lapply(raleigh_df[, c(9:27)], function(col) factor(col))

#Rating should be numeric
raleigh_df$Rating <- as.numeric(raleigh_df$Rating)
#Do forward selection for the columns that explain rating
full.model <- lm(Rating ~  ., data = raleigh_df[,c(2,4:5,9:26)])
empty.model <- lm(Rating ~ 1, data = raleigh_df[,c(2,4:5,9:26)])
for.model.raleigh <- step(empty.model, scope = list(lower = empty.model, upper = full.model), direction = "forward", k = 2)
step.model.raleigh <- step(empty.model, scope = list(lower = empty.model, upper = full.model), direction = "both", k = 2) 
```

### NYC Variable Selection
```{r, eval=FALSE, include=FALSE}
#import library
library("tidyverse")
#filter to only NYC variable selection
nyc_df <- boba2[boba2$source=="nyc_boba",]

nyc_df[, c(9:30)] <- lapply(nyc_df[, c(9:30)], function(col) factor(col))
#Rating should be numeric
nyc_df$Rating <- as.numeric(nyc_df$Rating)
#Do forward selection for the columns that explain rating
full.model.nyc <- lm(Rating ~  ., data = nyc_df[,c(3, 11:30)])
empty.model.nyc <- lm(Rating ~ 1, data = nyc_df[,c(2,9:30)])
for.model.nyc <- step(empty.model.nyc, scope = list(lower = empty.model.nyc, upper = full.model.nyc), direction = "forward", k = 2)
step.model.nyc <- step(empty.model.nyc, scope = list(lower = empty.model.nyc, upper = full.model.nyc), direction = "both", k = 2) 
```

The best linear regression for Raleigh had an AIC of -67.90 and five features of the juice bar/smoothie indicator, Asian fusion indicator, coffee/tea indicator, bakeries indicator, and tea room indicator. The best linear regression for NYC had an AIC of 19.72 and found the features of custom cakes indicator, authenticity, and chain. Among the two sites, there were eight distinct features observed in the complete variable selection models of all the variables in explaining the rating. None of these explanatory variables after selection were mutually shared.

## Predictive Random Forest Model
While random forest models are generally used for prediction, we used their ability to assess variable importance as a comparison point for the linear regression model. This ranking of variables was determined by the percent increase in the mean squared error (MSE). We assessed the variable importance of our predictive model output with a variable called “random”, seen in the plot of variable importance for NYC and Raleigh below.

### The Raleigh plot of variable importance is displayed below:
```{r, eval=FALSE, include=FALSE}
#import library
library(randomForest)
#Run a random forest model for Raleigh
raleigh_df<- as.data.frame(raleigh_df)
raleigh_df$random<- rnorm(43)
set.seed(12345)
rf.raleigh <- randomForest(Rating ~ ., data = raleigh_df, ntree = 250, importance = TRUE)
varImpPlot(rf.raleigh ,
           sort = TRUE,
           n.var = 10,
           main = "Top 10 - Variable Importance for Raleigh", type = 1)
```
The top important variables for the predictive model in Raleigh were similar to the linear regression model. Of the five explanatory variables of the linear regression (juice bar/smoothie indicator, Asian fusion indicator, coffee/tea indicator, bakeries indicator, and tea room indicator), four appeared before the random variable. A high overlap between explanatory and predictor variables allows us to infer that there are similar variables that go into forming and retaining a good Raleigh boba shop. These include:
- Having a variety of options, such as smoothies and juices.
- Appealing to the “fusion” audience rather than as an authentic boba shop.
- Location.
- Having food options, such as baked goods.
- Being tagged as a tea room.

### The NYC plot of variable importance is displayed below:
```{r, eval=FALSE, include=FALSE}
#import library
library(randomForest)
#Run a random forest model for NYC
nyc_df <- as.data.frame(nyc_df)
nyc_df$random<- rnorm(70)
set.seed(12345)
rf.nyc <- randomForest(Rating ~ ., data = nyc_df, ntree = 250, importance = TRUE)
varImpPlot(rf.nyc,
           sort = TRUE,
           n.var = 10,
           main = "Top 10 - Variable Importance for NYC", type = 1)
```
The top importance variables output from the random forest for New York City seemed to focus on location and authenticity, seen in the “longitude”, “city”, and “authenticity” variables. The custom cakes indicator also appeared before our random variable.

It’s important to note that the “city” variable was important in both the NYC and Raleigh variable importance outputs from our random forests; this may indicate that the shop’s location is a large factor in a Yelp rating. This output inspired us to visualize our data set and see the map of boba shops for both data sets.

## Visualization
We utilized the visualization platform Tableau to display both Raleigh and NYC boba shops by longitude and latitude. The feature cities in the data set indicated that Raleigh’s n = 44 boba shops spanned 9 towns, while NYC’s n = 70 boba shops spanned 10 neighborhoods. We noticed that shops in NYC tended to be more concentrated or in closer proximity to each other than shops in Raleigh. This indicates that there was more competition in close proximity in NYC than in Raleigh. This visualization reiterated the results from both the variable selection model and the predictive random forest model. The variable selection model displayed the most significant explanatory variables, indicating that there was a gap in features between locations.

The random forest model confirmed that the cities feature was important in mean boba shop rating outcomes, which could be attributed in part to physical shop proximity, as seen on the Tableau dashboard.



<!--chapter:end:03-results.Rmd-->

# Conclusion and Recommendations
## Findings
The boxplot in Figure 1 (Section 2.2) created questions around two main takeaways from our project: the mean ratings across locations and features to a linear explanatory model. We addressed:

 - The mean ratings across NYC and Raleigh.

 - Variable importance from the linear regression model and random forest model, where the linear regression model utilized stepwise selection to select significant explanatory variables with AIC metrics, and the random forest model confirmed that the cities feature was important in mean boba shop rating outcomes.

In Raleigh, Asian fusion and bakeries were important factors to secure high ratings. Conversely, in NYC, authenticity and the offering of custom cakes played key roles. These findings suggest that customers in NYC seem to have higher expectations as compared with customers in Raleigh, which was further supported after visual comparisons of each location data set.

We attribute the high overlap of the explanatory and predictive variables in part to physical shop proximity, as seen on the Tableau dashboard. This file is available in the Xiaolongbao repository, and you can find it in the file named "boba_tab.twbx" if additional loading is required.

## Next Steps
From our conclusion, we recommend that aspiring businesses considering a new boba shop could:

 - Understand the preferences and expectations of potential customers.
 
 - Prepare to face the competition in the area.

Our findings emphasize that what garners a high rating in one location may not necessarily translate to the same acclaim in another location, especially in densely populated cities.

Looking ahead, this project encourages future comparative studies of bubble tea shops in different areas across the country or even the world. Expanding the analysis to include major metropolitan locations like Los Angeles or Chicago could uncover broader trends in boba shop dynamics, providing entrepreneurs with valuable insights for navigating diverse urban landscapes. 

<!--chapter:end:04-conclusion.Rmd-->

# Acknowledgments
Dr. Labarr

Dr. Egan Warren

Dr. Healey

Tianyi Liu

Yang Chen

@gfairchild 

<!--chapter:end:05-acknowledgments.Rmd-->

